{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Language Detection as separate step from Transcription\n",
    "\n",
    "In this guide, we'll show you how to perform automatic language detection separately from the transcription process. For the transcription, the file then gets then routed to either our [*Best* or *Nano*](https://www.assemblyai.com/docs/speech-to-text/speech-recognition#select-the-speech-model-with-best-and-nano) model class, depending on the supported language.\n",
    "\n",
    "This workflow is designed to be cost-effective, slicing the first 60 seconds of audio and running it through Nano ALD, which detects 99 languages, at a cost of $0.002 per transcript for this language detection workflow (not including the total transcription cost).\n",
    "\n",
    "## Get started\n",
    "\n",
    "Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.\n",
    "\n",
    "## Step-by-step instructions\n",
    "\n",
    "Install the SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install assemblyai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `assemblyai` package and set your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "aai.settings.api_key = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set with all supported languages for *Best*. You can find them in our [documentation here](https://www.assemblyai.com/docs/concepts/supported-languages#supported-languages-for-best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_languages_for_best = {\n",
    "    \"en\",\n",
    "    \"en_au\",\n",
    "    \"en_uk\",\n",
    "    \"en_us\",\n",
    "    \"es\",\n",
    "    \"fr\",\n",
    "    \"de\",\n",
    "    \"it\",\n",
    "    \"pt\",\n",
    "    \"nl\",\n",
    "    \"hi\",\n",
    "    \"ja\",\n",
    "    \"zh\",\n",
    "    \"fi\",\n",
    "    \"ko\",\n",
    "    \"pl\",\n",
    "    \"ru\",\n",
    "    \"tr\",\n",
    "    \"uk\",\n",
    "    \"vi\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `Transcriber`. Note that here we don't pass in a global `TranscriptionConfig`, but later apply different ones during the `transcribe()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = aai.Transcriber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define two helper functions:\n",
    "- `detect_language()` performs language detection on the [first 60 seconds](https://www.assemblyai.com/docs/api-reference/transcripts/submit#request.body.audio_end_at) of the audio using *Nano* and returns the language code.\n",
    "- `transcribe_file()` performs the transcription. For this, the identified language is applied and either *Best* or *Nano* is used depending on the supported language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(audio_url):\n",
    "    config = aai.TranscriptionConfig(\n",
    "        audio_end_at=60000,  # first 60 seconds (in milliseconds)\n",
    "        language_detection=True,\n",
    "        speech_model=aai.SpeechModel.nano,\n",
    "    )\n",
    "    transcript = transcriber.transcribe(audio_url, config=config)\n",
    "    return transcript.json_response[\"language_code\"]\n",
    "\n",
    "def transcribe_file(audio_url, language_code):\n",
    "    config = aai.TranscriptionConfig(\n",
    "        language_code=language_code,\n",
    "        speech_model=(\n",
    "            aai.SpeechModel.best\n",
    "            if language_code in supported_languages_for_best\n",
    "            else aai.SpeechModel.nano\n",
    "        ),\n",
    "    )\n",
    "    transcript = transcriber.transcribe(audio_url, config=config)\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the code with different audio files. For each file, we apply both helper functions sequentially to first identify the language and then transcribe the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified language: pt\n",
      "Transcript: e aí Olá pessoal, sejam bem-vindos a mais um vídeo e hoje eu vou ensinar-vos como fazer esta espada  ...\n",
      "Identified language: es\n",
      "Transcript: Precisamente sobre este caso, el diario estadounidense New York Times reveló este sábado un conjunto ...\n",
      "Identified language: sl\n",
      "Transcript: Ni lepška, kaj videl tega otroka v mrekoj svojga okolja, da mu je uspil in to v takimi miri, da pač  ...\n",
      "Identified language: en\n",
      "Transcript: Runner's knee runner's knee is a condition characterized by pain behind or around the kneecap. It is ...\n"
     ]
    }
   ],
   "source": [
    "audio_urls = [\n",
    "    \"https://storage.googleapis.com/aai-web-samples/public_benchmarking_portugese.mp3\",\n",
    "    \"https://storage.googleapis.com/aai-web-samples/public_benchmarking_spanish.mp3\",\n",
    "    \"https://storage.googleapis.com/aai-web-samples/slovenian_luka_doncic_interview.mp3\",\n",
    "    \"https://storage.googleapis.com/aai-web-samples/5_common_sports_injuries.mp3\",\n",
    "]\n",
    "\n",
    "for audio_url in audio_urls:\n",
    "    language_code = detect_language(audio_url)\n",
    "    print(\"Identified language:\", language_code)\n",
    "\n",
    "    transcript = transcribe_file(audio_url, language_code)\n",
    "    print(\"Transcript:\", transcript.text[:100], \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
